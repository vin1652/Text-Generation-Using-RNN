{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgNL28CEpdiN"
      },
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UPNJ9czPpd5G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zDoXwHAKpmqA"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load data\n",
        "with open('/content/alllines.txt', 'r') as f:\n",
        "    doc = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpbPrVSuz3hO",
        "outputId": "66e89f0a-5632-44c9-86a8-cbc698d27eb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of text: 4583798 characters\n"
          ]
        }
      ],
      "source": [
        "print(f'Length of text: {len(doc)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjX0ZwYnz8ah",
        "outputId": "06711f35-54d3-48fb-9247-3e9cf4227b50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"ACT I\"\n",
            "\"SCENE I. London. The palace.\"\n",
            "\"Enter KING HENRY, LORD JOHN OF LANCASTER, the EARL of WESTMORELAND, SIR WALTER BLUNT, and others\"\n",
            "\"So shaken as we are, so wan with care,\"\n",
            "\"Find we a time for frighted peace to pant,\"\n",
            "\"And breathe short-winded \n"
          ]
        }
      ],
      "source": [
        "print(doc[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVATmz-d0IRL",
        "outputId": "cba5693f-e5c2-46ac-9437-f990b0c73f33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "78 unique characters\n"
          ]
        }
      ],
      "source": [
        "# The unique characters in the file\n",
        "vocab1 = sorted(set(doc))\n",
        "print(f'{len(vocab1)} unique characters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jd7dML_opqz8"
      },
      "source": [
        "## Text data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_FlK7JoFpw1x"
      },
      "outputs": [],
      "source": [
        "# Text preparation\n",
        "def doc2words(doc):\n",
        "    lines = doc.split('\\n')\n",
        "    lines = [line.strip(r'\\\"') for line in lines]\n",
        "    words = ' '.join(lines).split()\n",
        "    return words\n",
        "\n",
        "def removepunct(words):\n",
        "    punct = set(string.punctuation)\n",
        "    words = [''.join([char for char in list(word) if char not in punct]) for word in words]\n",
        "    return words\n",
        "\n",
        "def getvocab(words):\n",
        "    wordfreq = Counter(words)\n",
        "    sorted_wordfreq = sorted(wordfreq, key=wordfreq.get)\n",
        "    return sorted_wordfreq\n",
        "\n",
        "def vocab_map(vocab):\n",
        "    int_to_vocab = {k: w for k, w in enumerate(vocab)}\n",
        "    vocab_to_int = {w: k for k, w in int_to_vocab.items()}\n",
        "    return int_to_vocab, vocab_to_int\n",
        "\n",
        "words = removepunct(doc2words(doc))\n",
        "vocab = getvocab(words)\n",
        "int_to_vocab, vocab_to_int = vocab_map(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQNneVjHpxzZ"
      },
      "source": [
        "## Dataset Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bDS318E4fGX1"
      },
      "outputs": [],
      "source": [
        "#Dataset preparation\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, words, vocab_to_int, seq_size, batch_size):\n",
        "        self.words = words\n",
        "        self.vocab_to_int = vocab_to_int\n",
        "        self.seq_size = seq_size\n",
        "        self.batch_size = batch_size\n",
        "        self.x_data, self.y_data = self.preprocess_data()\n",
        "\n",
        "    def preprocess_data(self):\n",
        "        word_ints = [self.vocab_to_int[word] for word in self.words]\n",
        "        num_batches = int(len(word_ints) / (self.batch_size * self.seq_size))\n",
        "        Xs = word_ints[:num_batches * self.batch_size * self.seq_size]\n",
        "        Ys = np.zeros_like(Xs)\n",
        "        Ys[:-1] = Xs[1:]\n",
        "        Ys[-1] = Xs[0]\n",
        "        Xs = np.reshape(Xs, (num_batches * self.batch_size, self.seq_size))\n",
        "        Ys = np.reshape(Ys, (num_batches * self.batch_size, self.seq_size))\n",
        "        return Xs, Ys\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x_data[idx], self.y_data[idx]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQjk1Dzfp9MG"
      },
      "source": [
        "## Define RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "X7LRpyYOp_i6"
      },
      "outputs": [],
      "source": [
        "# Define RNN models\n",
        "class RNNModule(nn.Module):\n",
        "    def __init__(self, n_vocab, seq_size=32, embedding_size=64, lstm_size=128, num_layers=1, model_type='RNN', dropout=0.5):\n",
        "        super(RNNModule, self).__init__()\n",
        "        self.seq_size = seq_size\n",
        "        self.lstm_size = lstm_size\n",
        "        self.num_layers = num_layers\n",
        "        self.model_type = model_type\n",
        "        self.embedding = nn.Embedding(n_vocab, embedding_size)\n",
        "        if model_type == 'LSTM':\n",
        "            self.rnn = nn.LSTM(embedding_size, lstm_size, num_layers=num_layers, dropout=dropout, batch_first=True)\n",
        "        elif model_type == 'GRU':\n",
        "            self.rnn = nn.GRU(embedding_size, lstm_size, num_layers=num_layers, dropout=dropout, batch_first=True)\n",
        "        else:\n",
        "            self.rnn = nn.RNN(embedding_size, lstm_size, num_layers=num_layers, dropout=dropout, batch_first=True)\n",
        "        self.dense = nn.Linear(lstm_size, n_vocab)\n",
        "\n",
        "    def forward(self, x, prev_state):\n",
        "        embed = self.embedding(x)\n",
        "        output, state = self.rnn(embed, prev_state)\n",
        "        logits = self.dense(output)\n",
        "        return logits, state\n",
        "\n",
        "    def zero_state(self, batch_size):\n",
        "        if self.model_type == 'LSTM':\n",
        "            return (torch.zeros(self.num_layers, batch_size, self.lstm_size).to(device),\n",
        "                    torch.zeros(self.num_layers, batch_size, self.lstm_size).to(device))\n",
        "        else:\n",
        "            return torch.zeros(self.num_layers, batch_size, self.lstm_size).to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtfSwI0TqNDE"
      },
      "source": [
        "## Train and Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WOyxJawmqQCU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define training and evaluation functions\n",
        "def get_loss_and_train_op(net, lr=0.001, weight_decay=1e-4):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    return criterion, optimizer\n",
        "\n",
        "def train_model(model, criterion, optimizer, trainloader, valloader, epochs=50, patience=5, clip=5):\n",
        "    model = model.to(device)\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    best_model_state = None\n",
        "    best_model_path = 'best_model.pth'\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for x, y in trainloader:\n",
        "            state = model.zero_state(x.size(0))\n",
        "            if isinstance(state, tuple):\n",
        "                state = (state[0].to(device), state[1].to(device))\n",
        "            else:\n",
        "                state = state.to(device)\n",
        "\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output, state = model(x, state)\n",
        "            loss = criterion(output.transpose(1, 2), y)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "            optimizer.step()\n",
        "\n",
        "            if isinstance(state, tuple):\n",
        "                state = (state[0].detach(), state[1].detach())\n",
        "            else:\n",
        "                state = state.detach()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_losses.append(running_loss / len(trainloader))\n",
        "        val_loss, val_accuracy = evaluate_model(model, valloader, criterion)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        print(f'Epoch: {epoch + 1}, Training Loss: {train_losses[-1]:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_state = model.state_dict()\n",
        "            patience_counter = 0\n",
        "            torch.save(best_model_state, best_model_path)\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(\"Early stopping\")\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(torch.load(best_model_path))\n",
        "    return model, train_losses, val_losses\n",
        "\n",
        "def evaluate_model(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            state = model.zero_state(x.size(0))\n",
        "            if isinstance(state, tuple):\n",
        "                state = (state[0].to(device), state[1].to(device))\n",
        "            else:\n",
        "                state = state.to(device)\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            output, state = model(x, state)\n",
        "            loss = criterion(output.transpose(1, 2), y)\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(output, 2)\n",
        "            total += y.size(0) * y.size(1)\n",
        "            correct += (predicted == y).sum().item()\n",
        "    return total_loss / len(dataloader), correct / total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOMzUeTjqUM9"
      },
      "source": [
        "## Computing Perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ja-AhOcLqW70"
      },
      "outputs": [],
      "source": [
        "def compute_perplexity(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_words = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            state = model.zero_state(x.size(0))\n",
        "            if isinstance(state, tuple):\n",
        "                state = (state[0].to(device), state[1].to(device))\n",
        "            else:\n",
        "                state = state.to(device)\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            output, state = model(x, state)\n",
        "            loss = criterion(output.transpose(1, 2), y)\n",
        "            total_loss += loss.item() * y.size(0) * y.size(1)\n",
        "            total_words += y.size(0) * y.size(1)\n",
        "    perplexity = np.exp(total_loss / total_words)\n",
        "    return perplexity\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFsCmNCqqZH4"
      },
      "source": [
        "## Generate Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3552CwplqbXn"
      },
      "outputs": [],
      "source": [
        "# Generate text\n",
        "def generate_text(device, net, words, n_vocab, vocab_to_int, int_to_vocab, top_k=5):\n",
        "    net.eval()\n",
        "    state = net.zero_state(1)\n",
        "    if isinstance(state, tuple):\n",
        "        state = (state[0].to(device), state[1].to(device))\n",
        "    else:\n",
        "        state = state.to(device)\n",
        "    for w in words:\n",
        "        ix = torch.tensor([[vocab_to_int[w]]]).to(device)\n",
        "        output, state = net(ix, state)\n",
        "\n",
        "    _, top_ix = torch.topk(output[0], k=top_k)\n",
        "    choices = top_ix.tolist()\n",
        "    choice = np.random.choice(choices[0])\n",
        "\n",
        "    words.append(int_to_vocab[choice])\n",
        "\n",
        "    for _ in range(100):\n",
        "        ix = torch.tensor([[choice]]).to(device)\n",
        "        output, state = net(ix, state)\n",
        "\n",
        "        _, top_ix = torch.topk(output[0], k=top_k)\n",
        "        choices = top_ix.tolist()\n",
        "        choice = np.random.choice(choices[0])\n",
        "        words.append(int_to_vocab[choice])\n",
        "\n",
        "    print(' '.join(words))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CaMFrBqqcn1"
      },
      "source": [
        "## Testing Different Models - RNN, LSTM, GRU with different Architectures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vMsy5rrvgCx0",
        "outputId": "947a733b-5aaf-4ecc-8f14-9ca1ac7cc1a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training LSTM model with batch_size=16, seq_size=32, embedding_size=64, lstm_size=128, num_layers=1\n",
            "Epoch: 1, Training Loss: 6.8411, Validation Loss: 6.6249, Validation Accuracy: 0.0791\n",
            "Epoch: 2, Training Loss: 6.6018, Validation Loss: 6.5675, Validation Accuracy: 0.0820\n",
            "Epoch: 3, Training Loss: 6.5603, Validation Loss: 6.5331, Validation Accuracy: 0.0864\n",
            "Epoch: 4, Training Loss: 6.5409, Validation Loss: 6.5173, Validation Accuracy: 0.0867\n",
            "Epoch: 5, Training Loss: 6.5306, Validation Loss: 6.5166, Validation Accuracy: 0.0887\n",
            "Epoch: 6, Training Loss: 6.5238, Validation Loss: 6.5017, Validation Accuracy: 0.0900\n",
            "Epoch: 7, Training Loss: 6.5164, Validation Loss: 6.5039, Validation Accuracy: 0.0910\n",
            "Epoch: 8, Training Loss: 6.5084, Validation Loss: 6.4987, Validation Accuracy: 0.0907\n",
            "Epoch: 9, Training Loss: 6.5007, Validation Loss: 6.4880, Validation Accuracy: 0.0907\n",
            "Epoch: 10, Training Loss: 6.4949, Validation Loss: 6.4825, Validation Accuracy: 0.0901\n",
            "Epoch: 11, Training Loss: 6.4880, Validation Loss: 6.4705, Validation Accuracy: 0.0935\n",
            "Epoch: 12, Training Loss: 6.4809, Validation Loss: 6.4653, Validation Accuracy: 0.0927\n",
            "Epoch: 13, Training Loss: 6.4765, Validation Loss: 6.4659, Validation Accuracy: 0.0920\n",
            "Epoch: 14, Training Loss: 6.4695, Validation Loss: 6.4617, Validation Accuracy: 0.0927\n",
            "Epoch: 15, Training Loss: 6.4643, Validation Loss: 6.4650, Validation Accuracy: 0.0896\n",
            "Epoch: 16, Training Loss: 6.4616, Validation Loss: 6.4516, Validation Accuracy: 0.0919\n",
            "Epoch: 17, Training Loss: 6.4585, Validation Loss: 6.4489, Validation Accuracy: 0.0916\n",
            "Epoch: 18, Training Loss: 6.4586, Validation Loss: 6.4446, Validation Accuracy: 0.0941\n",
            "Epoch: 19, Training Loss: 6.4556, Validation Loss: 6.4446, Validation Accuracy: 0.0925\n",
            "Epoch: 20, Training Loss: 6.4546, Validation Loss: 6.4529, Validation Accuracy: 0.0917\n",
            "Epoch: 21, Training Loss: 6.4521, Validation Loss: 6.4448, Validation Accuracy: 0.0948\n",
            "Early stopping\n",
            "LSTM model perplexity: 628.5574\n",
            "Training LSTM model with batch_size=16, seq_size=32, embedding_size=64, lstm_size=128, num_layers=2\n",
            "Epoch: 1, Training Loss: 6.9716, Validation Loss: 6.6545, Validation Accuracy: 0.0738\n",
            "Epoch: 2, Training Loss: 6.6266, Validation Loss: 6.5739, Validation Accuracy: 0.0787\n",
            "Epoch: 3, Training Loss: 6.5674, Validation Loss: 6.5231, Validation Accuracy: 0.0828\n",
            "Epoch: 4, Training Loss: 6.5364, Validation Loss: 6.4940, Validation Accuracy: 0.0869\n",
            "Epoch: 5, Training Loss: 6.5161, Validation Loss: 6.4821, Validation Accuracy: 0.0868\n",
            "Epoch: 6, Training Loss: 6.5012, Validation Loss: 6.4645, Validation Accuracy: 0.0891\n",
            "Epoch: 7, Training Loss: 6.4915, Validation Loss: 6.4626, Validation Accuracy: 0.0880\n",
            "Epoch: 8, Training Loss: 6.4834, Validation Loss: 6.4512, Validation Accuracy: 0.0901\n",
            "Epoch: 9, Training Loss: 6.4772, Validation Loss: 6.4485, Validation Accuracy: 0.0896\n",
            "Epoch: 10, Training Loss: 6.4753, Validation Loss: 6.4433, Validation Accuracy: 0.0900\n",
            "Epoch: 11, Training Loss: 6.4721, Validation Loss: 6.4420, Validation Accuracy: 0.0912\n",
            "Epoch: 12, Training Loss: 6.4670, Validation Loss: 6.4465, Validation Accuracy: 0.0889\n",
            "Epoch: 13, Training Loss: 6.4675, Validation Loss: 6.4359, Validation Accuracy: 0.0901\n",
            "Epoch: 14, Training Loss: 6.4657, Validation Loss: 6.4375, Validation Accuracy: 0.0899\n",
            "Epoch: 15, Training Loss: 6.4631, Validation Loss: 6.4409, Validation Accuracy: 0.0902\n",
            "Epoch: 16, Training Loss: 6.4619, Validation Loss: 6.4312, Validation Accuracy: 0.0909\n",
            "Epoch: 17, Training Loss: 6.4609, Validation Loss: 6.4367, Validation Accuracy: 0.0904\n",
            "Epoch: 18, Training Loss: 6.4598, Validation Loss: 6.4366, Validation Accuracy: 0.0916\n",
            "Epoch: 19, Training Loss: 6.4581, Validation Loss: 6.4381, Validation Accuracy: 0.0909\n",
            "Early stopping\n",
            "LSTM model perplexity: 620.4424\n",
            "Training LSTM model with batch_size=16, seq_size=32, embedding_size=64, lstm_size=128, num_layers=3\n",
            "Epoch: 1, Training Loss: 7.1829, Validation Loss: 6.8147, Validation Accuracy: 0.0575\n",
            "Epoch: 2, Training Loss: 6.7261, Validation Loss: 6.6556, Validation Accuracy: 0.0737\n",
            "Epoch: 3, Training Loss: 6.6453, Validation Loss: 6.6022, Validation Accuracy: 0.0780\n",
            "Epoch: 4, Training Loss: 6.6164, Validation Loss: 6.5878, Validation Accuracy: 0.0792\n",
            "Epoch: 5, Training Loss: 6.6025, Validation Loss: 6.5718, Validation Accuracy: 0.0798\n",
            "Epoch: 6, Training Loss: 6.5905, Validation Loss: 6.5678, Validation Accuracy: 0.0803\n",
            "Epoch: 7, Training Loss: 6.5845, Validation Loss: 6.5581, Validation Accuracy: 0.0799\n",
            "Epoch: 8, Training Loss: 6.5764, Validation Loss: 6.5512, Validation Accuracy: 0.0813\n",
            "Epoch: 9, Training Loss: 6.5693, Validation Loss: 6.5525, Validation Accuracy: 0.0816\n",
            "Epoch: 10, Training Loss: 6.5650, Validation Loss: 6.5276, Validation Accuracy: 0.0819\n",
            "Epoch: 11, Training Loss: 6.5603, Validation Loss: 6.5312, Validation Accuracy: 0.0827\n",
            "Epoch: 12, Training Loss: 6.5556, Validation Loss: 6.5242, Validation Accuracy: 0.0837\n",
            "Epoch: 13, Training Loss: 6.5516, Validation Loss: 6.5285, Validation Accuracy: 0.0836\n",
            "Epoch: 14, Training Loss: 6.5483, Validation Loss: 6.5198, Validation Accuracy: 0.0842\n",
            "Epoch: 15, Training Loss: 6.5470, Validation Loss: 6.5144, Validation Accuracy: 0.0844\n",
            "Epoch: 16, Training Loss: 6.5454, Validation Loss: 6.5303, Validation Accuracy: 0.0817\n",
            "Epoch: 17, Training Loss: 6.5434, Validation Loss: 6.5169, Validation Accuracy: 0.0828\n",
            "Epoch: 18, Training Loss: 6.5417, Validation Loss: 6.5263, Validation Accuracy: 0.0834\n",
            "Early stopping\n",
            "LSTM model perplexity: 673.5579\n",
            "Training LSTM model with batch_size=16, seq_size=32, embedding_size=64, lstm_size=256, num_layers=1\n",
            "Epoch: 1, Training Loss: 6.8151, Validation Loss: 6.6364, Validation Accuracy: 0.0812\n",
            "Epoch: 2, Training Loss: 6.5750, Validation Loss: 6.5843, Validation Accuracy: 0.0837\n",
            "Epoch: 3, Training Loss: 6.5334, Validation Loss: 6.5434, Validation Accuracy: 0.0879\n",
            "Epoch: 4, Training Loss: 6.5104, Validation Loss: 6.5252, Validation Accuracy: 0.0874\n",
            "Epoch: 5, Training Loss: 6.4898, Validation Loss: 6.5017, Validation Accuracy: 0.0907\n",
            "Epoch: 6, Training Loss: 6.4711, Validation Loss: 6.4969, Validation Accuracy: 0.0900\n",
            "Epoch: 7, Training Loss: 6.4575, Validation Loss: 6.4782, Validation Accuracy: 0.0912\n",
            "Epoch: 8, Training Loss: 6.4441, Validation Loss: 6.4673, Validation Accuracy: 0.0918\n",
            "Epoch: 9, Training Loss: 6.4329, Validation Loss: 6.4779, Validation Accuracy: 0.0914\n",
            "Epoch: 10, Training Loss: 6.4273, Validation Loss: 6.4642, Validation Accuracy: 0.0929\n",
            "Epoch: 11, Training Loss: 6.4234, Validation Loss: 6.4588, Validation Accuracy: 0.0924\n",
            "Epoch: 12, Training Loss: 6.4203, Validation Loss: 6.4546, Validation Accuracy: 0.0937\n",
            "Epoch: 13, Training Loss: 6.4174, Validation Loss: 6.4409, Validation Accuracy: 0.0948\n",
            "Epoch: 14, Training Loss: 6.4143, Validation Loss: 6.4478, Validation Accuracy: 0.0930\n",
            "Epoch: 15, Training Loss: 6.4124, Validation Loss: 6.4420, Validation Accuracy: 0.0944\n",
            "Epoch: 16, Training Loss: 6.4109, Validation Loss: 6.4315, Validation Accuracy: 0.0953\n",
            "Epoch: 17, Training Loss: 6.4083, Validation Loss: 6.4314, Validation Accuracy: 0.0938\n",
            "Epoch: 18, Training Loss: 6.4053, Validation Loss: 6.4347, Validation Accuracy: 0.0936\n",
            "Epoch: 19, Training Loss: 6.4032, Validation Loss: 6.4383, Validation Accuracy: 0.0926\n",
            "Epoch: 20, Training Loss: 6.4015, Validation Loss: 6.4405, Validation Accuracy: 0.0938\n",
            "Early stopping\n",
            "LSTM model perplexity: 621.4990\n",
            "Training LSTM model with batch_size=16, seq_size=32, embedding_size=64, lstm_size=256, num_layers=2\n",
            "Epoch: 1, Training Loss: 6.9257, Validation Loss: 6.6577, Validation Accuracy: 0.0729\n",
            "Epoch: 2, Training Loss: 6.6337, Validation Loss: 6.5710, Validation Accuracy: 0.0801\n",
            "Epoch: 3, Training Loss: 6.5786, Validation Loss: 6.5332, Validation Accuracy: 0.0821\n",
            "Epoch: 4, Training Loss: 6.5474, Validation Loss: 6.5106, Validation Accuracy: 0.0860\n",
            "Epoch: 5, Training Loss: 6.5293, Validation Loss: 6.4912, Validation Accuracy: 0.0876\n",
            "Epoch: 6, Training Loss: 6.5187, Validation Loss: 6.4840, Validation Accuracy: 0.0882\n",
            "Epoch: 7, Training Loss: 6.5070, Validation Loss: 6.4805, Validation Accuracy: 0.0875\n",
            "Epoch: 8, Training Loss: 6.4978, Validation Loss: 6.4667, Validation Accuracy: 0.0904\n",
            "Epoch: 9, Training Loss: 6.4906, Validation Loss: 6.4592, Validation Accuracy: 0.0908\n",
            "Epoch: 10, Training Loss: 6.4859, Validation Loss: 6.4506, Validation Accuracy: 0.0921\n",
            "Epoch: 11, Training Loss: 6.4808, Validation Loss: 6.4570, Validation Accuracy: 0.0905\n",
            "Epoch: 12, Training Loss: 6.4787, Validation Loss: 6.4486, Validation Accuracy: 0.0914\n",
            "Epoch: 13, Training Loss: 6.4767, Validation Loss: 6.4445, Validation Accuracy: 0.0914\n",
            "Epoch: 14, Training Loss: 6.4754, Validation Loss: 6.4430, Validation Accuracy: 0.0907\n",
            "Epoch: 15, Training Loss: 6.4741, Validation Loss: 6.4570, Validation Accuracy: 0.0897\n",
            "Epoch: 16, Training Loss: 6.4723, Validation Loss: 6.4439, Validation Accuracy: 0.0907\n",
            "Epoch: 17, Training Loss: 6.4703, Validation Loss: 6.4415, Validation Accuracy: 0.0912\n",
            "Epoch: 18, Training Loss: 6.4731, Validation Loss: 6.4514, Validation Accuracy: 0.0895\n",
            "Epoch: 19, Training Loss: 6.4694, Validation Loss: 6.4381, Validation Accuracy: 0.0914\n",
            "Epoch: 20, Training Loss: 6.4700, Validation Loss: 6.4356, Validation Accuracy: 0.0893\n",
            "Epoch: 21, Training Loss: 6.4653, Validation Loss: 6.4381, Validation Accuracy: 0.0913\n",
            "Epoch: 22, Training Loss: 6.4652, Validation Loss: 6.4454, Validation Accuracy: 0.0918\n",
            "Epoch: 23, Training Loss: 6.4634, Validation Loss: 6.4303, Validation Accuracy: 0.0921\n",
            "Epoch: 24, Training Loss: 6.4615, Validation Loss: 6.4358, Validation Accuracy: 0.0923\n",
            "Epoch: 25, Training Loss: 6.4609, Validation Loss: 6.4345, Validation Accuracy: 0.0897\n",
            "LSTM model perplexity: 620.3228\n",
            "Training LSTM model with batch_size=16, seq_size=32, embedding_size=64, lstm_size=256, num_layers=3\n",
            "Epoch: 1, Training Loss: 7.0140, Validation Loss: 6.7208, Validation Accuracy: 0.0663\n",
            "Epoch: 2, Training Loss: 6.6979, Validation Loss: 6.6353, Validation Accuracy: 0.0730\n",
            "Epoch: 3, Training Loss: 6.6449, Validation Loss: 6.6056, Validation Accuracy: 0.0771\n",
            "Epoch: 4, Training Loss: 6.6206, Validation Loss: 6.5778, Validation Accuracy: 0.0790\n",
            "Epoch: 5, Training Loss: 6.6061, Validation Loss: 6.5673, Validation Accuracy: 0.0795\n",
            "Epoch: 6, Training Loss: 6.5962, Validation Loss: 6.5553, Validation Accuracy: 0.0819\n",
            "Epoch: 7, Training Loss: 6.5917, Validation Loss: 6.5473, Validation Accuracy: 0.0821\n",
            "Epoch: 8, Training Loss: 6.5856, Validation Loss: 6.5487, Validation Accuracy: 0.0814\n",
            "Epoch: 9, Training Loss: 6.5829, Validation Loss: 6.5461, Validation Accuracy: 0.0802\n",
            "Epoch: 10, Training Loss: 6.5778, Validation Loss: 6.5402, Validation Accuracy: 0.0821\n",
            "Epoch: 11, Training Loss: 6.5770, Validation Loss: 6.5455, Validation Accuracy: 0.0803\n",
            "Epoch: 12, Training Loss: 6.5745, Validation Loss: 6.5385, Validation Accuracy: 0.0815\n",
            "Epoch: 13, Training Loss: 6.5727, Validation Loss: 6.5476, Validation Accuracy: 0.0820\n",
            "Epoch: 14, Training Loss: 6.5713, Validation Loss: 6.5354, Validation Accuracy: 0.0825\n",
            "Epoch: 15, Training Loss: 6.5708, Validation Loss: 6.5456, Validation Accuracy: 0.0818\n",
            "Epoch: 16, Training Loss: 6.5710, Validation Loss: 6.5434, Validation Accuracy: 0.0821\n",
            "Epoch: 17, Training Loss: 6.5684, Validation Loss: 6.5233, Validation Accuracy: 0.0848\n",
            "Epoch: 18, Training Loss: 6.5675, Validation Loss: 6.5240, Validation Accuracy: 0.0839\n",
            "Epoch: 19, Training Loss: 6.5666, Validation Loss: 6.5319, Validation Accuracy: 0.0825\n",
            "Epoch: 20, Training Loss: 6.5664, Validation Loss: 6.5536, Validation Accuracy: 0.0805\n",
            "Early stopping\n",
            "LSTM model perplexity: 681.3264\n",
            "Training LSTM model with batch_size=16, seq_size=32, embedding_size=128, lstm_size=128, num_layers=1\n",
            "Epoch: 1, Training Loss: 6.8048, Validation Loss: 6.6145, Validation Accuracy: 0.0816\n",
            "Epoch: 2, Training Loss: 6.5752, Validation Loss: 6.5684, Validation Accuracy: 0.0840\n",
            "Epoch: 3, Training Loss: 6.5363, Validation Loss: 6.5319, Validation Accuracy: 0.0892\n",
            "Epoch: 4, Training Loss: 6.5163, Validation Loss: 6.5312, Validation Accuracy: 0.0866\n",
            "Epoch: 5, Training Loss: 6.5044, Validation Loss: 6.5085, Validation Accuracy: 0.0892\n",
            "Epoch: 6, Training Loss: 6.4968, Validation Loss: 6.5108, Validation Accuracy: 0.0857\n",
            "Epoch: 7, Training Loss: 6.4908, Validation Loss: 6.4961, Validation Accuracy: 0.0902\n",
            "Epoch: 8, Training Loss: 6.4819, Validation Loss: 6.4893, Validation Accuracy: 0.0892\n",
            "Epoch: 9, Training Loss: 6.4734, Validation Loss: 6.4749, Validation Accuracy: 0.0893\n",
            "Epoch: 10, Training Loss: 6.4677, Validation Loss: 6.4767, Validation Accuracy: 0.0919\n",
            "Epoch: 11, Training Loss: 6.4618, Validation Loss: 6.4805, Validation Accuracy: 0.0903\n",
            "Epoch: 12, Training Loss: 6.4584, Validation Loss: 6.4756, Validation Accuracy: 0.0910\n",
            "Early stopping\n",
            "LSTM model perplexity: 648.6124\n",
            "Training LSTM model with batch_size=16, seq_size=32, embedding_size=128, lstm_size=128, num_layers=2\n",
            "Epoch: 1, Training Loss: 6.9499, Validation Loss: 6.6388, Validation Accuracy: 0.0749\n",
            "Epoch: 2, Training Loss: 6.6166, Validation Loss: 6.5601, Validation Accuracy: 0.0808\n",
            "Epoch: 3, Training Loss: 6.5586, Validation Loss: 6.5196, Validation Accuracy: 0.0846\n",
            "Epoch: 4, Training Loss: 6.5271, Validation Loss: 6.4892, Validation Accuracy: 0.0862\n",
            "Epoch: 5, Training Loss: 6.5084, Validation Loss: 6.4762, Validation Accuracy: 0.0880\n",
            "Epoch: 6, Training Loss: 6.4950, Validation Loss: 6.4669, Validation Accuracy: 0.0883\n",
            "Epoch: 7, Training Loss: 6.4850, Validation Loss: 6.4519, Validation Accuracy: 0.0894\n",
            "Epoch: 8, Training Loss: 6.4779, Validation Loss: 6.4444, Validation Accuracy: 0.0905\n",
            "Epoch: 9, Training Loss: 6.4698, Validation Loss: 6.4418, Validation Accuracy: 0.0898\n",
            "Epoch: 10, Training Loss: 6.4637, Validation Loss: 6.4229, Validation Accuracy: 0.0911\n",
            "Epoch: 11, Training Loss: 6.4579, Validation Loss: 6.4305, Validation Accuracy: 0.0903\n",
            "Epoch: 12, Training Loss: 6.4560, Validation Loss: 6.4229, Validation Accuracy: 0.0921\n",
            "Epoch: 13, Training Loss: 6.4541, Validation Loss: 6.4231, Validation Accuracy: 0.0912\n",
            "Epoch: 14, Training Loss: 6.4524, Validation Loss: 6.4266, Validation Accuracy: 0.0916\n",
            "Epoch: 15, Training Loss: 6.4502, Validation Loss: 6.4196, Validation Accuracy: 0.0926\n",
            "Epoch: 16, Training Loss: 6.4485, Validation Loss: 6.4160, Validation Accuracy: 0.0925\n",
            "Epoch: 17, Training Loss: 6.4466, Validation Loss: 6.4041, Validation Accuracy: 0.0916\n",
            "Epoch: 18, Training Loss: 6.4453, Validation Loss: 6.4318, Validation Accuracy: 0.0901\n",
            "Epoch: 19, Training Loss: 6.4456, Validation Loss: 6.4128, Validation Accuracy: 0.0912\n",
            "Epoch: 20, Training Loss: 6.4445, Validation Loss: 6.4092, Validation Accuracy: 0.0915\n",
            "Early stopping\n",
            "LSTM model perplexity: 603.7138\n",
            "Training LSTM model with batch_size=16, seq_size=32, embedding_size=128, lstm_size=128, num_layers=3\n",
            "Epoch: 1, Training Loss: 7.0292, Validation Loss: 6.7304, Validation Accuracy: 0.0689\n",
            "Epoch: 2, Training Loss: 6.6983, Validation Loss: 6.6478, Validation Accuracy: 0.0732\n",
            "Epoch: 3, Training Loss: 6.6487, Validation Loss: 6.6048, Validation Accuracy: 0.0758\n",
            "Epoch: 4, Training Loss: 6.6218, Validation Loss: 6.5822, Validation Accuracy: 0.0791\n",
            "Epoch: 5, Training Loss: 6.6072, Validation Loss: 6.5716, Validation Accuracy: 0.0790\n",
            "Epoch: 6, Training Loss: 6.5967, Validation Loss: 6.5741, Validation Accuracy: 0.0802\n",
            "Epoch: 7, Training Loss: 6.5919, Validation Loss: 6.5643, Validation Accuracy: 0.0812\n",
            "Epoch: 8, Training Loss: 6.5846, Validation Loss: 6.5551, Validation Accuracy: 0.0786\n",
            "Epoch: 9, Training Loss: 6.5797, Validation Loss: 6.5484, Validation Accuracy: 0.0808\n",
            "Epoch: 10, Training Loss: 6.5746, Validation Loss: 6.5400, Validation Accuracy: 0.0824\n",
            "Epoch: 11, Training Loss: 6.5696, Validation Loss: 6.5393, Validation Accuracy: 0.0821\n",
            "Epoch: 12, Training Loss: 6.5646, Validation Loss: 6.5332, Validation Accuracy: 0.0812\n",
            "Epoch: 13, Training Loss: 6.5609, Validation Loss: 6.5386, Validation Accuracy: 0.0821\n",
            "Epoch: 14, Training Loss: 6.5572, Validation Loss: 6.5153, Validation Accuracy: 0.0837\n",
            "Epoch: 15, Training Loss: 6.5548, Validation Loss: 6.5239, Validation Accuracy: 0.0805\n",
            "Epoch: 16, Training Loss: 6.5530, Validation Loss: 6.5188, Validation Accuracy: 0.0835\n",
            "Epoch: 17, Training Loss: 6.5528, Validation Loss: 6.5143, Validation Accuracy: 0.0838\n",
            "Epoch: 18, Training Loss: 6.5484, Validation Loss: 6.5189, Validation Accuracy: 0.0821\n",
            "Epoch: 19, Training Loss: 6.5482, Validation Loss: 6.5201, Validation Accuracy: 0.0847\n",
            "Epoch: 20, Training Loss: 6.5486, Validation Loss: 6.5198, Validation Accuracy: 0.0832\n",
            "Early stopping\n",
            "LSTM model perplexity: 674.8520\n",
            "Training LSTM model with batch_size=16, seq_size=32, embedding_size=128, lstm_size=256, num_layers=1\n",
            "Epoch: 1, Training Loss: 6.7832, Validation Loss: 6.5963, Validation Accuracy: 0.0816\n",
            "Epoch: 2, Training Loss: 6.5744, Validation Loss: 6.5352, Validation Accuracy: 0.0858\n",
            "Epoch: 3, Training Loss: 6.5313, Validation Loss: 6.4916, Validation Accuracy: 0.0881\n",
            "Epoch: 4, Training Loss: 6.5062, Validation Loss: 6.4854, Validation Accuracy: 0.0889\n",
            "Epoch: 5, Training Loss: 6.4926, Validation Loss: 6.4676, Validation Accuracy: 0.0902\n",
            "Epoch: 6, Training Loss: 6.4786, Validation Loss: 6.4605, Validation Accuracy: 0.0909\n",
            "Epoch: 7, Training Loss: 6.4642, Validation Loss: 6.4435, Validation Accuracy: 0.0910\n",
            "Epoch: 8, Training Loss: 6.4581, Validation Loss: 6.4449, Validation Accuracy: 0.0913\n",
            "Epoch: 9, Training Loss: 6.4511, Validation Loss: 6.4400, Validation Accuracy: 0.0927\n",
            "Epoch: 10, Training Loss: 6.4455, Validation Loss: 6.4418, Validation Accuracy: 0.0914\n",
            "Epoch: 11, Training Loss: 6.4424, Validation Loss: 6.4261, Validation Accuracy: 0.0943\n",
            "Epoch: 12, Training Loss: 6.4374, Validation Loss: 6.4264, Validation Accuracy: 0.0927\n",
            "Epoch: 13, Training Loss: 6.4344, Validation Loss: 6.4158, Validation Accuracy: 0.0930\n",
            "Epoch: 14, Training Loss: 6.4303, Validation Loss: 6.4256, Validation Accuracy: 0.0932\n",
            "Epoch: 15, Training Loss: 6.4276, Validation Loss: 6.4138, Validation Accuracy: 0.0942\n",
            "Epoch: 16, Training Loss: 6.4263, Validation Loss: 6.4186, Validation Accuracy: 0.0929\n",
            "Epoch: 17, Training Loss: 6.4224, Validation Loss: 6.4168, Validation Accuracy: 0.0940\n",
            "Epoch: 18, Training Loss: 6.4216, Validation Loss: 6.4043, Validation Accuracy: 0.0949\n",
            "Epoch: 19, Training Loss: 6.4203, Validation Loss: 6.4201, Validation Accuracy: 0.0938\n",
            "Epoch: 20, Training Loss: 6.4199, Validation Loss: 6.4031, Validation Accuracy: 0.0954\n",
            "Epoch: 21, Training Loss: 6.4193, Validation Loss: 6.4105, Validation Accuracy: 0.0946\n",
            "Epoch: 22, Training Loss: 6.4182, Validation Loss: 6.4096, Validation Accuracy: 0.0937\n",
            "Epoch: 23, Training Loss: 6.4163, Validation Loss: 6.4024, Validation Accuracy: 0.0930\n",
            "Epoch: 24, Training Loss: 6.4154, Validation Loss: 6.4133, Validation Accuracy: 0.0931\n",
            "Epoch: 25, Training Loss: 6.4139, Validation Loss: 6.4093, Validation Accuracy: 0.0934\n",
            "LSTM model perplexity: 603.0788\n",
            "Training LSTM model with batch_size=16, seq_size=32, embedding_size=128, lstm_size=256, num_layers=2\n",
            "Epoch: 1, Training Loss: 6.9068, Validation Loss: 6.6362, Validation Accuracy: 0.0754\n",
            "Epoch: 2, Training Loss: 6.6047, Validation Loss: 6.5569, Validation Accuracy: 0.0812\n",
            "Epoch: 3, Training Loss: 6.5527, Validation Loss: 6.5164, Validation Accuracy: 0.0834\n",
            "Epoch: 4, Training Loss: 6.5264, Validation Loss: 6.4879, Validation Accuracy: 0.0877\n",
            "Epoch: 5, Training Loss: 6.5115, Validation Loss: 6.4862, Validation Accuracy: 0.0859\n",
            "Epoch: 6, Training Loss: 6.5003, Validation Loss: 6.4758, Validation Accuracy: 0.0868\n",
            "Epoch: 7, Training Loss: 6.4945, Validation Loss: 6.4714, Validation Accuracy: 0.0862\n",
            "Epoch: 8, Training Loss: 6.4865, Validation Loss: 6.4621, Validation Accuracy: 0.0887\n",
            "Epoch: 9, Training Loss: 6.4806, Validation Loss: 6.4508, Validation Accuracy: 0.0882\n",
            "Epoch: 10, Training Loss: 6.4725, Validation Loss: 6.4505, Validation Accuracy: 0.0892\n",
            "Epoch: 11, Training Loss: 6.4707, Validation Loss: 6.4470, Validation Accuracy: 0.0894\n",
            "Epoch: 12, Training Loss: 6.4671, Validation Loss: 6.4495, Validation Accuracy: 0.0889\n",
            "Epoch: 13, Training Loss: 6.4670, Validation Loss: 6.4460, Validation Accuracy: 0.0898\n",
            "Epoch: 14, Training Loss: 6.4622, Validation Loss: 6.4414, Validation Accuracy: 0.0902\n",
            "Epoch: 15, Training Loss: 6.4606, Validation Loss: 6.4369, Validation Accuracy: 0.0913\n",
            "Epoch: 16, Training Loss: 6.4593, Validation Loss: 6.4353, Validation Accuracy: 0.0892\n",
            "Epoch: 17, Training Loss: 6.4571, Validation Loss: 6.4410, Validation Accuracy: 0.0898\n",
            "Epoch: 18, Training Loss: 6.4554, Validation Loss: 6.4285, Validation Accuracy: 0.0921\n",
            "Epoch: 19, Training Loss: 6.4556, Validation Loss: 6.4383, Validation Accuracy: 0.0912\n",
            "Epoch: 20, Training Loss: 6.4548, Validation Loss: 6.4313, Validation Accuracy: 0.0903\n",
            "Epoch: 21, Training Loss: 6.4520, Validation Loss: 6.4234, Validation Accuracy: 0.0916\n",
            "Epoch: 22, Training Loss: 6.4510, Validation Loss: 6.4369, Validation Accuracy: 0.0907\n",
            "Epoch: 23, Training Loss: 6.4498, Validation Loss: 6.4219, Validation Accuracy: 0.0902\n",
            "Epoch: 24, Training Loss: 6.4479, Validation Loss: 6.4295, Validation Accuracy: 0.0898\n",
            "Epoch: 25, Training Loss: 6.4481, Validation Loss: 6.4290, Validation Accuracy: 0.0911\n",
            "LSTM model perplexity: 615.3657\n",
            "Training LSTM model with batch_size=16, seq_size=32, embedding_size=128, lstm_size=256, num_layers=3\n",
            "Epoch: 1, Training Loss: 6.9901, Validation Loss: 6.7215, Validation Accuracy: 0.0666\n",
            "Epoch: 2, Training Loss: 6.6847, Validation Loss: 6.6448, Validation Accuracy: 0.0747\n",
            "Epoch: 3, Training Loss: 6.6402, Validation Loss: 6.6088, Validation Accuracy: 0.0781\n",
            "Epoch: 4, Training Loss: 6.6138, Validation Loss: 6.5834, Validation Accuracy: 0.0806\n",
            "Epoch: 5, Training Loss: 6.6026, Validation Loss: 6.5771, Validation Accuracy: 0.0796\n",
            "Epoch: 6, Training Loss: 6.5927, Validation Loss: 6.5754, Validation Accuracy: 0.0794\n",
            "Epoch: 7, Training Loss: 6.5867, Validation Loss: 6.5695, Validation Accuracy: 0.0798\n",
            "Epoch: 8, Training Loss: 6.5837, Validation Loss: 6.5573, Validation Accuracy: 0.0804\n",
            "Epoch: 9, Training Loss: 6.5797, Validation Loss: 6.5658, Validation Accuracy: 0.0792\n",
            "Epoch: 10, Training Loss: 6.5765, Validation Loss: 6.5562, Validation Accuracy: 0.0827\n",
            "Epoch: 11, Training Loss: 6.5753, Validation Loss: 6.5470, Validation Accuracy: 0.0814\n",
            "Epoch: 12, Training Loss: 6.5731, Validation Loss: 6.5535, Validation Accuracy: 0.0814\n",
            "Epoch: 13, Training Loss: 6.5733, Validation Loss: 6.5559, Validation Accuracy: 0.0804\n",
            "Epoch: 14, Training Loss: 6.5712, Validation Loss: 6.5653, Validation Accuracy: 0.0804\n",
            "Early stopping\n",
            "LSTM model perplexity: 696.5352\n",
            "Training GRU model with batch_size=16, seq_size=32, embedding_size=64, lstm_size=128, num_layers=1\n",
            "Epoch: 1, Training Loss: 6.7653, Validation Loss: 6.4896, Validation Accuracy: 0.0868\n",
            "Epoch: 2, Training Loss: 6.4181, Validation Loss: 6.3842, Validation Accuracy: 0.0957\n",
            "Epoch: 3, Training Loss: 6.3438, Validation Loss: 6.3487, Validation Accuracy: 0.0966\n",
            "Epoch: 4, Training Loss: 6.3130, Validation Loss: 6.3244, Validation Accuracy: 0.0994\n",
            "Epoch: 5, Training Loss: 6.2960, Validation Loss: 6.3054, Validation Accuracy: 0.0987\n",
            "Epoch: 6, Training Loss: 6.2838, Validation Loss: 6.3013, Validation Accuracy: 0.0985\n",
            "Epoch: 7, Training Loss: 6.2733, Validation Loss: 6.2916, Validation Accuracy: 0.1006\n",
            "Epoch: 8, Training Loss: 6.2678, Validation Loss: 6.2985, Validation Accuracy: 0.0997\n",
            "Epoch: 9, Training Loss: 6.2637, Validation Loss: 6.2998, Validation Accuracy: 0.0998\n",
            "Epoch: 10, Training Loss: 6.2610, Validation Loss: 6.2918, Validation Accuracy: 0.0985\n",
            "Early stopping\n",
            "GRU model perplexity: 539.8554\n",
            "Training GRU model with batch_size=16, seq_size=32, embedding_size=64, lstm_size=128, num_layers=2\n",
            "Epoch: 1, Training Loss: 6.9778, Validation Loss: 6.5820, Validation Accuracy: 0.0794\n",
            "Epoch: 2, Training Loss: 6.5561, Validation Loss: 6.4785, Validation Accuracy: 0.0845\n",
            "Epoch: 3, Training Loss: 6.4910, Validation Loss: 6.4483, Validation Accuracy: 0.0883\n",
            "Epoch: 4, Training Loss: 6.4631, Validation Loss: 6.4198, Validation Accuracy: 0.0893\n",
            "Epoch: 5, Training Loss: 6.4465, Validation Loss: 6.3985, Validation Accuracy: 0.0905\n",
            "Epoch: 6, Training Loss: 6.4403, Validation Loss: 6.4141, Validation Accuracy: 0.0910\n",
            "Epoch: 7, Training Loss: 6.4293, Validation Loss: 6.3998, Validation Accuracy: 0.0904\n",
            "Epoch: 8, Training Loss: 6.4216, Validation Loss: 6.3830, Validation Accuracy: 0.0913\n",
            "Epoch: 9, Training Loss: 6.4161, Validation Loss: 6.3902, Validation Accuracy: 0.0922\n",
            "Epoch: 10, Training Loss: 6.4140, Validation Loss: 6.3819, Validation Accuracy: 0.0930\n",
            "Epoch: 11, Training Loss: 6.4119, Validation Loss: 6.3767, Validation Accuracy: 0.0920\n",
            "Epoch: 12, Training Loss: 6.4133, Validation Loss: 6.3779, Validation Accuracy: 0.0923\n",
            "Epoch: 13, Training Loss: 6.4124, Validation Loss: 6.3685, Validation Accuracy: 0.0937\n",
            "Epoch: 14, Training Loss: 6.4069, Validation Loss: 6.3739, Validation Accuracy: 0.0924\n",
            "Epoch: 15, Training Loss: 6.4107, Validation Loss: 6.3805, Validation Accuracy: 0.0937\n",
            "Epoch: 16, Training Loss: 6.4124, Validation Loss: 6.3784, Validation Accuracy: 0.0912\n",
            "Early stopping\n",
            "GRU model perplexity: 582.9596\n",
            "Training GRU model with batch_size=16, seq_size=32, embedding_size=64, lstm_size=128, num_layers=3\n",
            "Epoch: 1, Training Loss: 7.2502, Validation Loss: 7.0431, Validation Accuracy: 0.0436\n",
            "Epoch: 2, Training Loss: 6.9518, Validation Loss: 6.9145, Validation Accuracy: 0.0549\n",
            "Epoch: 3, Training Loss: 6.8590, Validation Loss: 6.8409, Validation Accuracy: 0.0624\n",
            "Epoch: 4, Training Loss: 6.8158, Validation Loss: 6.8239, Validation Accuracy: 0.0653\n",
            "Epoch: 5, Training Loss: 6.7927, Validation Loss: 6.7680, Validation Accuracy: 0.0677\n",
            "Epoch: 6, Training Loss: 6.7763, Validation Loss: 6.7619, Validation Accuracy: 0.0681\n",
            "Epoch: 7, Training Loss: 6.7597, Validation Loss: 6.7165, Validation Accuracy: 0.0707\n",
            "Epoch: 8, Training Loss: 6.7417, Validation Loss: 6.7595, Validation Accuracy: 0.0654\n",
            "Epoch: 9, Training Loss: 6.7432, Validation Loss: 6.7047, Validation Accuracy: 0.0719\n",
            "Epoch: 10, Training Loss: 6.7386, Validation Loss: 6.7349, Validation Accuracy: 0.0662\n",
            "Epoch: 11, Training Loss: 6.7334, Validation Loss: 6.7006, Validation Accuracy: 0.0699\n",
            "Epoch: 12, Training Loss: 6.7236, Validation Loss: 6.7116, Validation Accuracy: 0.0717\n",
            "Epoch: 13, Training Loss: 6.7139, Validation Loss: 6.6972, Validation Accuracy: 0.0725\n",
            "Epoch: 14, Training Loss: 6.7063, Validation Loss: 6.6392, Validation Accuracy: 0.0746\n",
            "Epoch: 15, Training Loss: 6.7030, Validation Loss: 6.6570, Validation Accuracy: 0.0738\n",
            "Epoch: 16, Training Loss: 6.6937, Validation Loss: 6.6598, Validation Accuracy: 0.0750\n",
            "Epoch: 17, Training Loss: 6.6944, Validation Loss: 6.6728, Validation Accuracy: 0.0741\n",
            "Early stopping\n",
            "GRU model perplexity: 764.6699\n",
            "Training GRU model with batch_size=16, seq_size=32, embedding_size=64, lstm_size=256, num_layers=1\n",
            "Epoch: 1, Training Loss: 6.6803, Validation Loss: 6.4443, Validation Accuracy: 0.0910\n",
            "Epoch: 2, Training Loss: 6.3923, Validation Loss: 6.3895, Validation Accuracy: 0.0911\n",
            "Epoch: 3, Training Loss: 6.3374, Validation Loss: 6.3332, Validation Accuracy: 0.0957\n",
            "Epoch: 4, Training Loss: 6.3093, Validation Loss: 6.3359, Validation Accuracy: 0.0967\n",
            "Epoch: 5, Training Loss: 6.2959, Validation Loss: 6.3209, Validation Accuracy: 0.0981\n",
            "Epoch: 6, Training Loss: 6.2865, Validation Loss: 6.3050, Validation Accuracy: 0.0992\n",
            "Epoch: 7, Training Loss: 6.2792, Validation Loss: 6.3068, Validation Accuracy: 0.0999\n",
            "Epoch: 8, Training Loss: 6.2757, Validation Loss: 6.3053, Validation Accuracy: 0.1000\n",
            "Epoch: 9, Training Loss: 6.2706, Validation Loss: 6.2997, Validation Accuracy: 0.0992\n",
            "Epoch: 10, Training Loss: 6.2685, Validation Loss: 6.2946, Validation Accuracy: 0.0991\n",
            "Epoch: 11, Training Loss: 6.2666, Validation Loss: 6.2895, Validation Accuracy: 0.0997\n",
            "Epoch: 12, Training Loss: 6.2648, Validation Loss: 6.2971, Validation Accuracy: 0.0990\n",
            "Epoch: 13, Training Loss: 6.2646, Validation Loss: 6.2822, Validation Accuracy: 0.0999\n",
            "Epoch: 14, Training Loss: 6.2634, Validation Loss: 6.2919, Validation Accuracy: 0.1008\n",
            "Epoch: 15, Training Loss: 6.2604, Validation Loss: 6.2949, Validation Accuracy: 0.1011\n",
            "Epoch: 16, Training Loss: 6.2581, Validation Loss: 6.2808, Validation Accuracy: 0.1010\n",
            "Epoch: 17, Training Loss: 6.2582, Validation Loss: 6.2930, Validation Accuracy: 0.0993\n",
            "Epoch: 18, Training Loss: 6.2574, Validation Loss: 6.2937, Validation Accuracy: 0.1011\n",
            "Epoch: 19, Training Loss: 6.2561, Validation Loss: 6.2906, Validation Accuracy: 0.1002\n",
            "Early stopping\n",
            "GRU model perplexity: 533.6784\n",
            "Training GRU model with batch_size=16, seq_size=32, embedding_size=64, lstm_size=256, num_layers=2\n",
            "Epoch: 1, Training Loss: 7.0788, Validation Loss: 6.7835, Validation Accuracy: 0.0663\n",
            "Epoch: 2, Training Loss: 6.7333, Validation Loss: 6.6729, Validation Accuracy: 0.0725\n",
            "Epoch: 3, Training Loss: 6.6490, Validation Loss: 6.6455, Validation Accuracy: 0.0797\n",
            "Epoch: 4, Training Loss: 6.6181, Validation Loss: 6.6337, Validation Accuracy: 0.0781\n",
            "Epoch: 5, Training Loss: 6.5948, Validation Loss: 6.5593, Validation Accuracy: 0.0808\n",
            "Epoch: 6, Training Loss: 6.5849, Validation Loss: 6.5692, Validation Accuracy: 0.0784\n",
            "Epoch: 7, Training Loss: 6.5642, Validation Loss: 6.5551, Validation Accuracy: 0.0799\n",
            "Epoch: 8, Training Loss: 6.5624, Validation Loss: 6.5476, Validation Accuracy: 0.0836\n",
            "Epoch: 9, Training Loss: 6.5528, Validation Loss: 6.5331, Validation Accuracy: 0.0832\n",
            "Epoch: 10, Training Loss: 6.5441, Validation Loss: 6.5386, Validation Accuracy: 0.0834\n",
            "Epoch: 11, Training Loss: 6.5512, Validation Loss: 6.5317, Validation Accuracy: 0.0846\n",
            "Epoch: 12, Training Loss: 6.5393, Validation Loss: 6.5678, Validation Accuracy: 0.0827\n",
            "Epoch: 13, Training Loss: 6.5394, Validation Loss: 6.5121, Validation Accuracy: 0.0849\n",
            "Epoch: 14, Training Loss: 6.5353, Validation Loss: 6.5099, Validation Accuracy: 0.0830\n",
            "Epoch: 15, Training Loss: 6.5279, Validation Loss: 6.5012, Validation Accuracy: 0.0858\n",
            "Epoch: 16, Training Loss: 6.5245, Validation Loss: 6.5090, Validation Accuracy: 0.0859\n",
            "Epoch: 17, Training Loss: 6.5172, Validation Loss: 6.5065, Validation Accuracy: 0.0843\n",
            "Epoch: 18, Training Loss: 6.5221, Validation Loss: 6.5240, Validation Accuracy: 0.0844\n",
            "Early stopping\n",
            "GRU model perplexity: 666.1320\n",
            "Training GRU model with batch_size=16, seq_size=32, embedding_size=64, lstm_size=256, num_layers=3\n",
            "Epoch: 1, Training Loss: 7.4548, Validation Loss: 7.4406, Validation Accuracy: 0.0196\n",
            "Epoch: 2, Training Loss: 7.3793, Validation Loss: 7.3348, Validation Accuracy: 0.0223\n",
            "Epoch: 3, Training Loss: 7.3673, Validation Loss: 7.3777, Validation Accuracy: 0.0289\n",
            "Epoch: 4, Training Loss: 7.3558, Validation Loss: 7.4383, Validation Accuracy: 0.0245\n",
            "Epoch: 5, Training Loss: 7.4727, Validation Loss: 7.3594, Validation Accuracy: 0.0289\n",
            "Early stopping\n",
            "GRU model perplexity: 1533.4836\n",
            "Training GRU model with batch_size=16, seq_size=32, embedding_size=128, lstm_size=128, num_layers=1\n",
            "Epoch: 1, Training Loss: 6.7296, Validation Loss: 6.4840, Validation Accuracy: 0.0881\n",
            "Epoch: 2, Training Loss: 6.4285, Validation Loss: 6.3763, Validation Accuracy: 0.0931\n",
            "Epoch: 3, Training Loss: 6.3540, Validation Loss: 6.3379, Validation Accuracy: 0.0954\n",
            "Epoch: 4, Training Loss: 6.3221, Validation Loss: 6.3163, Validation Accuracy: 0.0974\n",
            "Epoch: 5, Training Loss: 6.3055, Validation Loss: 6.3082, Validation Accuracy: 0.0986\n",
            "Epoch: 6, Training Loss: 6.2944, Validation Loss: 6.3026, Validation Accuracy: 0.0971\n",
            "Epoch: 7, Training Loss: 6.2893, Validation Loss: 6.2977, Validation Accuracy: 0.0991\n",
            "Epoch: 8, Training Loss: 6.2810, Validation Loss: 6.2871, Validation Accuracy: 0.1000\n",
            "Epoch: 9, Training Loss: 6.2795, Validation Loss: 6.2838, Validation Accuracy: 0.0999\n",
            "Epoch: 10, Training Loss: 6.2750, Validation Loss: 6.2758, Validation Accuracy: 0.1006\n",
            "Epoch: 11, Training Loss: 6.2772, Validation Loss: 6.2838, Validation Accuracy: 0.1000\n",
            "Epoch: 12, Training Loss: 6.2739, Validation Loss: 6.2850, Validation Accuracy: 0.0987\n",
            "Epoch: 13, Training Loss: 6.2724, Validation Loss: 6.2781, Validation Accuracy: 0.1014\n",
            "Early stopping\n",
            "GRU model perplexity: 531.7212\n",
            "Training GRU model with batch_size=16, seq_size=32, embedding_size=128, lstm_size=128, num_layers=2\n",
            "Epoch: 1, Training Loss: 6.9635, Validation Loss: 6.6075, Validation Accuracy: 0.0793\n",
            "Epoch: 2, Training Loss: 6.5552, Validation Loss: 6.4803, Validation Accuracy: 0.0864\n",
            "Epoch: 3, Training Loss: 6.4904, Validation Loss: 6.4464, Validation Accuracy: 0.0889\n",
            "Epoch: 4, Training Loss: 6.4655, Validation Loss: 6.4257, Validation Accuracy: 0.0875\n",
            "Epoch: 5, Training Loss: 6.4483, Validation Loss: 6.4112, Validation Accuracy: 0.0920\n",
            "Epoch: 6, Training Loss: 6.4365, Validation Loss: 6.3980, Validation Accuracy: 0.0927\n",
            "Epoch: 7, Training Loss: 6.4324, Validation Loss: 6.4051, Validation Accuracy: 0.0921\n",
            "Epoch: 8, Training Loss: 6.4260, Validation Loss: 6.4060, Validation Accuracy: 0.0923\n",
            "Epoch: 9, Training Loss: 6.4255, Validation Loss: 6.3918, Validation Accuracy: 0.0926\n",
            "Epoch: 10, Training Loss: 6.4202, Validation Loss: 6.3895, Validation Accuracy: 0.0932\n",
            "Epoch: 11, Training Loss: 6.4197, Validation Loss: 6.3874, Validation Accuracy: 0.0926\n",
            "Epoch: 12, Training Loss: 6.4220, Validation Loss: 6.3910, Validation Accuracy: 0.0916\n",
            "Epoch: 13, Training Loss: 6.4194, Validation Loss: 6.3915, Validation Accuracy: 0.0937\n",
            "Epoch: 14, Training Loss: 6.4158, Validation Loss: 6.3859, Validation Accuracy: 0.0923\n",
            "Epoch: 15, Training Loss: 6.4130, Validation Loss: 6.3835, Validation Accuracy: 0.0933\n",
            "Epoch: 16, Training Loss: 6.4152, Validation Loss: 6.3945, Validation Accuracy: 0.0920\n",
            "Epoch: 17, Training Loss: 6.4131, Validation Loss: 6.3881, Validation Accuracy: 0.0931\n",
            "Epoch: 18, Training Loss: 6.4111, Validation Loss: 6.3855, Validation Accuracy: 0.0941\n",
            "Early stopping\n",
            "GRU model perplexity: 591.9791\n",
            "Training GRU model with batch_size=16, seq_size=32, embedding_size=128, lstm_size=128, num_layers=3\n",
            "Epoch: 1, Training Loss: 7.4148, Validation Loss: 7.3502, Validation Accuracy: 0.0291\n",
            "Epoch: 2, Training Loss: 7.3287, Validation Loss: 7.3177, Validation Accuracy: 0.0275\n",
            "Epoch: 3, Training Loss: 7.3220, Validation Loss: 7.3079, Validation Accuracy: 0.0240\n",
            "Epoch: 4, Training Loss: 7.3217, Validation Loss: 7.3251, Validation Accuracy: 0.0291\n",
            "Epoch: 5, Training Loss: 7.3230, Validation Loss: 7.3765, Validation Accuracy: 0.0240\n",
            "Epoch: 6, Training Loss: 7.3214, Validation Loss: 7.3382, Validation Accuracy: 0.0240\n",
            "Early stopping\n",
            "GRU model perplexity: 1491.8560\n",
            "Training GRU model with batch_size=16, seq_size=32, embedding_size=128, lstm_size=256, num_layers=1\n",
            "Epoch: 1, Training Loss: 6.6676, Validation Loss: 6.4324, Validation Accuracy: 0.0892\n",
            "Epoch: 2, Training Loss: 6.3908, Validation Loss: 6.3703, Validation Accuracy: 0.0929\n",
            "Epoch: 3, Training Loss: 6.3383, Validation Loss: 6.3429, Validation Accuracy: 0.0956\n",
            "Epoch: 4, Training Loss: 6.3118, Validation Loss: 6.3194, Validation Accuracy: 0.0968\n",
            "Epoch: 5, Training Loss: 6.2964, Validation Loss: 6.2971, Validation Accuracy: 0.0991\n",
            "Epoch: 6, Training Loss: 6.2881, Validation Loss: 6.3042, Validation Accuracy: 0.0984\n",
            "Epoch: 7, Training Loss: 6.2823, Validation Loss: 6.2963, Validation Accuracy: 0.1002\n",
            "Epoch: 8, Training Loss: 6.2787, Validation Loss: 6.2990, Validation Accuracy: 0.0985\n",
            "Epoch: 9, Training Loss: 6.2750, Validation Loss: 6.2854, Validation Accuracy: 0.0992\n",
            "Epoch: 10, Training Loss: 6.2735, Validation Loss: 6.2781, Validation Accuracy: 0.1013\n",
            "Epoch: 11, Training Loss: 6.2712, Validation Loss: 6.2874, Validation Accuracy: 0.1001\n",
            "Epoch: 12, Training Loss: 6.2703, Validation Loss: 6.2802, Validation Accuracy: 0.0999\n",
            "Epoch: 13, Training Loss: 6.2688, Validation Loss: 6.2799, Validation Accuracy: 0.1003\n",
            "Early stopping\n",
            "GRU model perplexity: 531.9664\n",
            "Training GRU model with batch_size=16, seq_size=32, embedding_size=128, lstm_size=256, num_layers=2\n",
            "Epoch: 1, Training Loss: 7.0787, Validation Loss: 6.7896, Validation Accuracy: 0.0673\n",
            "Epoch: 2, Training Loss: 6.7359, Validation Loss: 6.6499, Validation Accuracy: 0.0757\n",
            "Epoch: 3, Training Loss: 6.6450, Validation Loss: 6.5633, Validation Accuracy: 0.0742\n",
            "Epoch: 4, Training Loss: 6.6005, Validation Loss: 6.5725, Validation Accuracy: 0.0790\n",
            "Epoch: 5, Training Loss: 6.5671, Validation Loss: 6.5282, Validation Accuracy: 0.0802\n",
            "Epoch: 6, Training Loss: 6.5499, Validation Loss: 6.4922, Validation Accuracy: 0.0816\n",
            "Epoch: 7, Training Loss: 6.5405, Validation Loss: 6.5204, Validation Accuracy: 0.0825\n",
            "Epoch: 8, Training Loss: 6.5244, Validation Loss: 6.4790, Validation Accuracy: 0.0846\n",
            "Epoch: 9, Training Loss: 6.5170, Validation Loss: 6.5193, Validation Accuracy: 0.0832\n",
            "Epoch: 10, Training Loss: 6.5081, Validation Loss: 6.4482, Validation Accuracy: 0.0882\n",
            "Epoch: 11, Training Loss: 6.5099, Validation Loss: 6.5234, Validation Accuracy: 0.0825\n",
            "Epoch: 12, Training Loss: 6.5061, Validation Loss: 6.4522, Validation Accuracy: 0.0874\n",
            "Epoch: 13, Training Loss: 6.4968, Validation Loss: 6.4833, Validation Accuracy: 0.0855\n",
            "Early stopping\n",
            "GRU model perplexity: 631.9314\n",
            "Training GRU model with batch_size=16, seq_size=32, embedding_size=128, lstm_size=256, num_layers=3\n",
            "Epoch: 1, Training Loss: 7.3096, Validation Loss: 7.1540, Validation Accuracy: 0.0371\n",
            "Epoch: 2, Training Loss: 7.0600, Validation Loss: 6.9636, Validation Accuracy: 0.0426\n",
            "Epoch: 3, Training Loss: 6.9828, Validation Loss: 6.9341, Validation Accuracy: 0.0519\n",
            "Epoch: 4, Training Loss: 6.9517, Validation Loss: 6.9366, Validation Accuracy: 0.0539\n",
            "Epoch: 5, Training Loss: 6.9423, Validation Loss: 6.9089, Validation Accuracy: 0.0521\n",
            "Epoch: 6, Training Loss: 6.9386, Validation Loss: 6.8989, Validation Accuracy: 0.0508\n",
            "Epoch: 7, Training Loss: 6.9228, Validation Loss: 6.9696, Validation Accuracy: 0.0485\n",
            "Epoch: 8, Training Loss: 6.9313, Validation Loss: 6.9389, Validation Accuracy: 0.0493\n",
            "Epoch: 9, Training Loss: 6.9222, Validation Loss: 6.8752, Validation Accuracy: 0.0510\n",
            "Epoch: 10, Training Loss: 6.9221, Validation Loss: 6.8698, Validation Accuracy: 0.0522\n",
            "Epoch: 11, Training Loss: 6.9086, Validation Loss: 6.8662, Validation Accuracy: 0.0510\n",
            "Epoch: 12, Training Loss: 6.9195, Validation Loss: 6.8617, Validation Accuracy: 0.0532\n",
            "Epoch: 13, Training Loss: 6.9138, Validation Loss: 6.8795, Validation Accuracy: 0.0549\n",
            "Epoch: 14, Training Loss: 6.8986, Validation Loss: 6.8384, Validation Accuracy: 0.0593\n",
            "Epoch: 15, Training Loss: 6.8982, Validation Loss: 6.8610, Validation Accuracy: 0.0580\n",
            "Epoch: 16, Training Loss: 6.8861, Validation Loss: 6.8563, Validation Accuracy: 0.0560\n",
            "Epoch: 17, Training Loss: 6.8754, Validation Loss: 6.9037, Validation Accuracy: 0.0565\n",
            "Early stopping\n",
            "GRU model perplexity: 933.1531\n",
            "Training RNN model with batch_size=16, seq_size=32, embedding_size=64, lstm_size=128, num_layers=1\n",
            "Epoch: 1, Training Loss: 7.5900, Validation Loss: 7.4753, Validation Accuracy: 0.0477\n",
            "Epoch: 2, Training Loss: 7.4689, Validation Loss: 7.7941, Validation Accuracy: 0.0343\n",
            "Epoch: 3, Training Loss: 7.5690, Validation Loss: 7.7836, Validation Accuracy: 0.0370\n",
            "Epoch: 4, Training Loss: 7.7500, Validation Loss: 7.6575, Validation Accuracy: 0.0279\n",
            "Early stopping\n",
            "RNN model perplexity: 1763.6457\n",
            "Training RNN model with batch_size=16, seq_size=32, embedding_size=64, lstm_size=128, num_layers=2\n",
            "Epoch: 1, Training Loss: 7.8358, Validation Loss: 7.7598, Validation Accuracy: 0.0247\n",
            "Epoch: 2, Training Loss: 7.8069, Validation Loss: 7.7917, Validation Accuracy: 0.0266\n",
            "Epoch: 3, Training Loss: 7.7591, Validation Loss: 7.7115, Validation Accuracy: 0.0260\n",
            "Epoch: 4, Training Loss: 7.7122, Validation Loss: 7.7112, Validation Accuracy: 0.0272\n",
            "Epoch: 5, Training Loss: 7.6506, Validation Loss: 7.5609, Validation Accuracy: 0.0265\n",
            "Epoch: 6, Training Loss: 7.5968, Validation Loss: 7.6904, Validation Accuracy: 0.0264\n",
            "Epoch: 7, Training Loss: 7.6187, Validation Loss: 7.6648, Validation Accuracy: 0.0209\n",
            "Epoch: 8, Training Loss: 7.5698, Validation Loss: 7.5874, Validation Accuracy: 0.0244\n",
            "Early stopping\n",
            "RNN model perplexity: 1921.2284\n",
            "Training RNN model with batch_size=16, seq_size=32, embedding_size=64, lstm_size=128, num_layers=3\n",
            "Epoch: 1, Training Loss: 7.9286, Validation Loss: 7.8741, Validation Accuracy: 0.0225\n",
            "Epoch: 2, Training Loss: 7.9071, Validation Loss: 7.7737, Validation Accuracy: 0.0221\n",
            "Epoch: 3, Training Loss: 7.8260, Validation Loss: 7.7356, Validation Accuracy: 0.0216\n",
            "Epoch: 4, Training Loss: 7.7263, Validation Loss: 7.8033, Validation Accuracy: 0.0207\n",
            "Epoch: 5, Training Loss: 7.6058, Validation Loss: 7.6389, Validation Accuracy: 0.0165\n",
            "Epoch: 6, Training Loss: 7.5865, Validation Loss: 7.6014, Validation Accuracy: 0.0189\n",
            "Epoch: 7, Training Loss: 7.6175, Validation Loss: 7.6048, Validation Accuracy: 0.0236\n",
            "Epoch: 8, Training Loss: 7.6267, Validation Loss: 7.5922, Validation Accuracy: 0.0227\n",
            "Epoch: 9, Training Loss: 7.6249, Validation Loss: 7.6355, Validation Accuracy: 0.0219\n",
            "Epoch: 10, Training Loss: 7.5912, Validation Loss: 7.5377, Validation Accuracy: 0.0270\n",
            "Epoch: 11, Training Loss: 7.6431, Validation Loss: 7.7001, Validation Accuracy: 0.0218\n",
            "Epoch: 12, Training Loss: 7.6032, Validation Loss: 7.5618, Validation Accuracy: 0.0223\n",
            "Epoch: 13, Training Loss: 7.6005, Validation Loss: 7.5849, Validation Accuracy: 0.0235\n",
            "Early stopping\n",
            "RNN model perplexity: 1875.6389\n",
            "Training RNN model with batch_size=16, seq_size=32, embedding_size=64, lstm_size=256, num_layers=1\n",
            "Epoch: 1, Training Loss: 8.8872, Validation Loss: 8.4698, Validation Accuracy: 0.0217\n",
            "Epoch: 2, Training Loss: 8.8081, Validation Loss: 8.2005, Validation Accuracy: 0.0256\n",
            "Epoch: 3, Training Loss: 8.7849, Validation Loss: 7.9483, Validation Accuracy: 0.0256\n",
            "Epoch: 4, Training Loss: 8.0669, Validation Loss: 8.1714, Validation Accuracy: 0.0329\n",
            "Epoch: 5, Training Loss: 9.0057, Validation Loss: 8.1873, Validation Accuracy: 0.0342\n",
            "Epoch: 6, Training Loss: 8.6344, Validation Loss: 8.5202, Validation Accuracy: 0.0332\n",
            "Early stopping\n",
            "RNN model perplexity: 2834.3634\n",
            "Training RNN model with batch_size=16, seq_size=32, embedding_size=64, lstm_size=256, num_layers=2\n",
            "Epoch: 1, Training Loss: 8.9204, Validation Loss: 9.5408, Validation Accuracy: 0.0003\n",
            "Epoch: 2, Training Loss: 8.7676, Validation Loss: 8.4779, Validation Accuracy: 0.0122\n",
            "Epoch: 3, Training Loss: 8.5744, Validation Loss: 9.7109, Validation Accuracy: 0.0223\n",
            "Epoch: 4, Training Loss: 8.9110, Validation Loss: 8.1676, Validation Accuracy: 0.0145\n",
            "Epoch: 5, Training Loss: 8.4155, Validation Loss: 8.3598, Validation Accuracy: 0.0085\n",
            "Epoch: 6, Training Loss: 8.3412, Validation Loss: 8.4249, Validation Accuracy: 0.0221\n",
            "Epoch: 7, Training Loss: 8.2552, Validation Loss: 8.3799, Validation Accuracy: 0.0109\n",
            "Early stopping\n",
            "RNN model perplexity: 3527.2209\n",
            "Training RNN model with batch_size=16, seq_size=32, embedding_size=64, lstm_size=256, num_layers=3\n",
            "Epoch: 1, Training Loss: 8.9330, Validation Loss: 8.7211, Validation Accuracy: 0.0243\n",
            "Epoch: 2, Training Loss: 8.5765, Validation Loss: 8.5995, Validation Accuracy: 0.0237\n",
            "Epoch: 3, Training Loss: 8.3230, Validation Loss: 8.4807, Validation Accuracy: 0.0182\n",
            "Epoch: 4, Training Loss: 8.2783, Validation Loss: 8.3864, Validation Accuracy: 0.0059\n",
            "Epoch: 5, Training Loss: 8.2706, Validation Loss: 8.2256, Validation Accuracy: 0.0133\n",
            "Epoch: 6, Training Loss: 8.2017, Validation Loss: 8.3431, Validation Accuracy: 0.0096\n",
            "Epoch: 7, Training Loss: 7.6425, Validation Loss: 7.3921, Validation Accuracy: 0.0245\n",
            "Epoch: 8, Training Loss: 7.5402, Validation Loss: 7.7072, Validation Accuracy: 0.0213\n",
            "Epoch: 9, Training Loss: 7.8882, Validation Loss: 7.7837, Validation Accuracy: 0.0180\n",
            "Epoch: 10, Training Loss: 8.2696, Validation Loss: 8.5145, Validation Accuracy: 0.0025\n",
            "Early stopping\n",
            "RNN model perplexity: 1622.9734\n",
            "Training RNN model with batch_size=16, seq_size=32, embedding_size=128, lstm_size=128, num_layers=1\n",
            "Epoch: 1, Training Loss: 7.5434, Validation Loss: 7.5013, Validation Accuracy: 0.0463\n",
            "Epoch: 2, Training Loss: 7.4575, Validation Loss: 7.4479, Validation Accuracy: 0.0419\n",
            "Epoch: 3, Training Loss: 7.4876, Validation Loss: 7.4187, Validation Accuracy: 0.0391\n",
            "Epoch: 4, Training Loss: 7.4598, Validation Loss: 7.4778, Validation Accuracy: 0.0422\n",
            "Epoch: 5, Training Loss: 7.5040, Validation Loss: 7.4923, Validation Accuracy: 0.0370\n",
            "Epoch: 6, Training Loss: 7.5517, Validation Loss: 7.6203, Validation Accuracy: 0.0370\n",
            "Early stopping\n",
            "RNN model perplexity: 1664.4179\n",
            "Training RNN model with batch_size=16, seq_size=32, embedding_size=128, lstm_size=128, num_layers=2\n",
            "Epoch: 1, Training Loss: 7.8154, Validation Loss: 7.8120, Validation Accuracy: 0.0300\n",
            "Epoch: 2, Training Loss: 7.7282, Validation Loss: 7.7488, Validation Accuracy: 0.0131\n",
            "Epoch: 3, Training Loss: 7.6136, Validation Loss: 7.5615, Validation Accuracy: 0.0294\n",
            "Epoch: 4, Training Loss: 7.5215, Validation Loss: 7.5521, Validation Accuracy: 0.0313\n",
            "Epoch: 5, Training Loss: 7.4998, Validation Loss: 7.4909, Validation Accuracy: 0.0334\n",
            "Epoch: 6, Training Loss: 7.4517, Validation Loss: 7.4975, Validation Accuracy: 0.0309\n",
            "Epoch: 7, Training Loss: 7.4447, Validation Loss: 7.4472, Validation Accuracy: 0.0350\n",
            "Epoch: 8, Training Loss: 7.4365, Validation Loss: 7.4287, Validation Accuracy: 0.0342\n",
            "Epoch: 9, Training Loss: 7.4810, Validation Loss: 7.5777, Validation Accuracy: 0.0258\n",
            "Epoch: 10, Training Loss: 7.5139, Validation Loss: 7.4008, Validation Accuracy: 0.0357\n",
            "Epoch: 11, Training Loss: 7.4631, Validation Loss: 7.4268, Validation Accuracy: 0.0362\n",
            "Epoch: 12, Training Loss: 7.5190, Validation Loss: 7.5535, Validation Accuracy: 0.0308\n",
            "Epoch: 13, Training Loss: 7.4754, Validation Loss: 7.4432, Validation Accuracy: 0.0280\n",
            "Early stopping\n",
            "RNN model perplexity: 1639.4450\n",
            "Training RNN model with batch_size=16, seq_size=32, embedding_size=128, lstm_size=128, num_layers=3\n",
            "Epoch: 1, Training Loss: 7.7157, Validation Loss: 7.7418, Validation Accuracy: 0.0160\n",
            "Epoch: 2, Training Loss: 7.7006, Validation Loss: 7.7476, Validation Accuracy: 0.0232\n",
            "Epoch: 3, Training Loss: 7.6261, Validation Loss: 7.6526, Validation Accuracy: 0.0209\n",
            "Epoch: 4, Training Loss: 7.5958, Validation Loss: 7.7413, Validation Accuracy: 0.0215\n",
            "Epoch: 5, Training Loss: 7.6492, Validation Loss: 7.6759, Validation Accuracy: 0.0156\n",
            "Epoch: 6, Training Loss: 7.6188, Validation Loss: 7.7272, Validation Accuracy: 0.0176\n",
            "Early stopping\n",
            "RNN model perplexity: 2108.2034\n",
            "Training RNN model with batch_size=16, seq_size=32, embedding_size=128, lstm_size=256, num_layers=1\n",
            "Epoch: 1, Training Loss: 8.6194, Validation Loss: 8.5882, Validation Accuracy: 0.0385\n",
            "Epoch: 2, Training Loss: 8.4305, Validation Loss: 8.6511, Validation Accuracy: 0.0151\n",
            "Epoch: 3, Training Loss: 8.6805, Validation Loss: 8.8216, Validation Accuracy: 0.0169\n",
            "Epoch: 4, Training Loss: 8.7917, Validation Loss: 8.8850, Validation Accuracy: 0.0302\n",
            "Early stopping\n",
            "RNN model perplexity: 5358.1673\n",
            "Training RNN model with batch_size=16, seq_size=32, embedding_size=128, lstm_size=256, num_layers=2\n",
            "Epoch: 1, Training Loss: 8.8485, Validation Loss: 9.1571, Validation Accuracy: 0.0282\n",
            "Epoch: 2, Training Loss: 9.1118, Validation Loss: 9.0790, Validation Accuracy: 0.0048\n",
            "Epoch: 3, Training Loss: 9.0137, Validation Loss: 9.3224, Validation Accuracy: 0.0258\n",
            "Epoch: 4, Training Loss: 8.4854, Validation Loss: 8.4068, Validation Accuracy: 0.0220\n",
            "Epoch: 5, Training Loss: 8.3690, Validation Loss: 8.7729, Validation Accuracy: 0.0123\n",
            "Epoch: 6, Training Loss: 7.5159, Validation Loss: 7.5019, Validation Accuracy: 0.0273\n",
            "Epoch: 7, Training Loss: 7.8146, Validation Loss: 9.0198, Validation Accuracy: 0.0036\n",
            "Epoch: 8, Training Loss: 8.2616, Validation Loss: 7.8415, Validation Accuracy: 0.0201\n",
            "Epoch: 9, Training Loss: 8.4061, Validation Loss: 8.1727, Validation Accuracy: 0.0157\n",
            "Early stopping\n",
            "RNN model perplexity: 1811.8924\n",
            "Training RNN model with batch_size=16, seq_size=32, embedding_size=128, lstm_size=256, num_layers=3\n",
            "Epoch: 1, Training Loss: 8.8244, Validation Loss: 8.7310, Validation Accuracy: 0.0243\n",
            "Epoch: 2, Training Loss: 8.9163, Validation Loss: 8.8115, Validation Accuracy: 0.0010\n",
            "Epoch: 3, Training Loss: 8.9403, Validation Loss: 8.9248, Validation Accuracy: 0.0149\n",
            "Epoch: 4, Training Loss: 9.0494, Validation Loss: 9.6431, Validation Accuracy: 0.0124\n",
            "Early stopping\n",
            "RNN model perplexity: 6192.5312\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Parameters\n",
        "batch_sizes = [16]\n",
        "seq_sizes = [32]\n",
        "embedding_sizes = [64, 128]\n",
        "lstm_sizes = [128, 256]\n",
        "num_layers_list = [1, 2, 3]\n",
        "\n",
        "\n",
        "# Track the best model based on perplexity\n",
        "best_model = None\n",
        "best_perplexity = float('inf')\n",
        "\n",
        "# Train and evaluate different models\n",
        "for model_type in ['LSTM', 'GRU','RNN']:\n",
        "    for batch_size in batch_sizes:\n",
        "        for seq_size in seq_sizes:\n",
        "            for embedding_size in embedding_sizes:\n",
        "                for lstm_size in lstm_sizes:\n",
        "                    for num_layers in num_layers_list:\n",
        "                        print(f'Training {model_type} model with batch_size={batch_size}, seq_size={seq_size}, embedding_size={embedding_size}, lstm_size={lstm_size}, num_layers={num_layers}')\n",
        "\n",
        "                        dataset = TextDataset(words, vocab_to_int, seq_size, batch_size)\n",
        "                        train_size = int(0.8 * len(dataset))\n",
        "                        val_size = len(dataset) - train_size\n",
        "                        train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "                        trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "                        valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "                        model = RNNModule(len(vocab), seq_size, embedding_size, lstm_size, num_layers, model_type, dropout=0.5).to(device)\n",
        "                        criterion, optimizer = get_loss_and_train_op(model, 0.01)\n",
        "                        model, train_losses, val_losses = train_model(model, criterion, optimizer, trainloader, valloader, epochs=25, patience=3, clip=5)\n",
        "\n",
        "                        perplexity = compute_perplexity(model, valloader, criterion)\n",
        "                        print(f'{model_type} model perplexity: {perplexity:.4f}')\n",
        "\n",
        "                        if perplexity < best_perplexity:\n",
        "                            best_perplexity = perplexity\n",
        "                            best_model = model\n",
        "                            best_train_losses = train_losses\n",
        "                            best_val_losses = val_losses\n",
        "\n",
        "# Plot the training and validation loss of the best model\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(best_train_losses, label='Training Loss')\n",
        "plt.plot(best_val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aeaVWuHqsRx"
      },
      "source": [
        "## Hyperparameter Tuning for Learning Rate, Drop out Rate and Weight Decay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bom6lEIKq0Ox",
        "outputId": "7d557cd7-ad7d-4026-be44-5bda92fdb1e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RNNModule(\n",
              "  (embedding): Embedding(32641, 128)\n",
              "  (rnn): GRU(128, 128, batch_first=True, dropout=0.5)\n",
              "  (dense): Linear(in_features=128, out_features=32641, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gf28O_FigxP"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "\n",
        "# Objective function for Optuna\n",
        "def objective(trial):\n",
        "    # Hyperparameters to tune\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 1e-1)\n",
        "    weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-2)\n",
        "    dropout = trial.suggest_uniform('dropout', 0.2, 0.7)\n",
        "\n",
        "    # Define model\n",
        "    model = RNNModule(len(vocab), seq_size=32, embedding_size=128, lstm_size=128, num_layers=1, model_type='GRU', dropout=dropout).to(device)\n",
        "    criterion, optimizer = get_loss_and_train_op(model, lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # Train model\n",
        "    _, train_losses, val_losses = train_model(model, criterion, optimizer, trainloader, valloader, epochs=50, patience=3, clip=5)\n",
        "\n",
        "    # Calculate validation loss\n",
        "    val_loss = val_losses[-1]\n",
        "\n",
        "    return val_loss\n",
        "\n",
        "# Create study and optimize\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# Best hyperparameters\n",
        "best_params = study.best_params\n",
        "print(\"Best hyperparameters: \", best_params)\n",
        "\n",
        "# Now you can use the best hyperparameters to train your final model\n",
        "best_model = RNNModule(len(vocab), seq_size=32, embedding_size=128, lstm_size=128, num_layers=1, model_type='GRU', dropout=best_params['dropout']).to(device)\n",
        "criterion, optimizer = get_loss_and_train_op(best_model, lr=best_params['learning_rate'], weight_decay=best_params['weight_decay'])\n",
        "best_model, train_losses, val_losses = train_model(best_model, criterion, optimizer, trainloader, valloader, epochs=50, patience=3, clip=5)\n",
        "\n",
        "# Plot the training and validation loss of the best model\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Rk3ytiQCqjf",
        "outputId": "afecf9e0-523e-4d2f-ac0c-28acda92c800"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RNNModule(\n",
              "  (embedding): Embedding(32641, 128)\n",
              "  (rnn): GRU(128, 128, batch_first=True, dropout=0.6)\n",
              "  (dense): Linear(in_features=128, out_features=32641, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rpYPNVVEdWo",
        "outputId": "6aa0117c-9a09-4cf6-decb-000296e34313"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To be so much to you my liege And all your highness pleasure and you are not to my heart To see this ring and I do accuse your grace I have my lord to be a servant to my heart To give me leave to you with me And in your power and you must not have no power of your love And give you love for me For your own life I am no more than yours To have you both to hear you I do not so far To make a gentle daughter and your highness And to the gods\n"
          ]
        }
      ],
      "source": [
        "# Generate text with the best model\n",
        "generate_text(device, best_model, ['To', 'be'], len(vocab), vocab_to_int, int_to_vocab, top_k=5)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
